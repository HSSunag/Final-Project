{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmented.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeMiuCPuX86YymWG0pOvJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSSunag/Final-Project/blob/master/augmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brhcJhmYMNgy",
        "colab_type": "code",
        "outputId": "db0cb4cc-14c8-447f-d012-d018cfb3f38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnefmDQyM0JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP-zQF5SNFi2",
        "colab_type": "code",
        "outputId": "130caeb1-7c2d-4f2a-9aff-c0e4f3e77842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(os.listdir('drive/My Drive/Datasets/Category1')))\n",
        "print(len(os.listdir('drive/My Drive/Datasets/Category2')))\n",
        "print(len(os.listdir('drive/My Drive/Datasets/Category3')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "270\n",
            "225\n",
            "234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKBUjHv8P46v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    #YOUR CODE GOES HERE\n",
        "    os.mkdir('drive/My Drive/Data')\n",
        "    training = os.path.join('drive/My Drive/Data','training')\n",
        "    testing = os.path.join('drive/My Drive/Data','testing')\n",
        "    os.mkdir(training)\n",
        "    os.mkdir(testing)\n",
        "    cat1 = os.path.join(training,'cat1')\n",
        "    cat2 = os.path.join(training,'cat2')\n",
        "    cat3 = os.path.join(training,'cat3')\n",
        "    cat12 = os.path.join(testing,'cat1')\n",
        "    cat22 = os.path.join(testing,'cat2')\n",
        "    cat32 = os.path.join(testing,'cat3')\n",
        "    os.mkdir(cat1)\n",
        "    os.mkdir(cat2)\n",
        "    os.mkdir(cat3)\n",
        "    os.mkdir(cat12)\n",
        "    os.mkdir(cat22)\n",
        "    os.mkdir(cat32)\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wHy10C8eyn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from shutil import copyfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXYKHsM0RbGB",
        "colab_type": "code",
        "outputId": "95bc6f53-e441-414d-85f3-fbe97f3d1d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 03:02:40--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 2607:f8b0:400c:c16::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  38%[======>             ]  32.01M   129MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   197MB/s    in 0.4s    \n",
            "\n",
            "2020-05-16 03:02:40 (197 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hiDzS6ISKPS",
        "colab_type": "code",
        "outputId": "043b927e-0df5-4e66-8f74-36195ec7b45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"drive/My Drive/Data/training\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255)\n",
        "\n",
        "VALIDATION_DIR = \"drive/My Drive/Data/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 584 images belonging to 3 classes.\n",
            "Found 145 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PILIYEKRrFR",
        "colab_type": "code",
        "outputId": "8546fa72-545a-43a8-c494-242cf8395d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (3, activation='softmax')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=3, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20/20 [==============================] - 696s 35s/step - loss: 8.1177 - accuracy: 0.7684 - val_loss: 2.9978 - val_accuracy: 0.4834\n",
            "Epoch 2/3\n",
            "20/20 [==============================] - 686s 34s/step - loss: 0.1644 - accuracy: 0.9696 - val_loss: 8.7798 - val_accuracy: 0.6347\n",
            "Epoch 3/3\n",
            "20/20 [==============================] - 687s 34s/step - loss: 1.2121 - accuracy: 0.9054 - val_loss: 3.8952 - val_accuracy: 0.4760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh4qcATZRQS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = os.listdir(SOURCE)\n",
        "    #random.sample(files, len(files))\n",
        "    training_files = SPLIT_SIZE*(len(files))\n",
        "    for i in range(0,len(files)):\n",
        "        if os.path.getsize(os.path.join(SOURCE,files[i])) == 0:\n",
        "            continue\n",
        "        if i < training_files:\n",
        "            copyfile(os.path.join(SOURCE,files[i]),os.path.join(TRAINING,files[i]))\n",
        "        if i>= training_files:\n",
        "            copyfile(os.path.join(SOURCE,files[i]),os.path.join(TESTING,files[i]))\n",
        "    \n",
        "# YOUR CODE STARTS HERE\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "CAT1_SOURCE_DIR = \"drive/My Drive/Datasets/Category1/\"\n",
        "CAT2_SOURCE_DIR = \"drive/My Drive/Datasets/Category2/\"\n",
        "CAT3_SOURCE_DIR = \"drive/My Drive/Datasets/Category3/\"\n",
        "TRAINING_CAT1_DIR = \"drive/My Drive/Data/training/cat1/\"\n",
        "TRAINING_CAT2_DIR = \"drive/My Drive/Data/training/cat2/\"\n",
        "TRAINING_CAT3_DIR = \"drive/My Drive/Data/training/cat3/\"\n",
        "TESTING_CAT1_DIR = \"drive/My Drive/Data/testing/cat1/\"\n",
        "TESTING_CAT2_DIR = \"drive/My Drive/Data/testing/cat2/\"\n",
        "TESTING_CAT3_DIR = \"drive/My Drive/Data/testing/cat3/\"\n",
        "\n",
        "\n",
        "split_size = .8\n",
        "split_data(\"drive/My Drive/Datasets/Category1/\", \"drive/My Drive/Data/training/cat1/\", \"drive/My Drive/Data/testing/cat1/\", split_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcrWDjtX-6TR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-l-28We-69r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_data(\"drive/My Drive/Datasets/Category2/\", \"drive/My Drive/Data/training/cat2/\", \"drive/My Drive/Data/testing/cat2/\", split_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUPUybpK_6ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_data(\"drive/My Drive/Datasets/Category3/\", \"drive/My Drive/Data/training/cat3/\", \"drive/My Drive/Data/testing/cat3/\", split_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXS_VCbHg7MK",
        "colab_type": "code",
        "outputId": "c9980994-a8ab-4b03-9e5c-585267ae31a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(len(os.listdir('drive/My Drive/Data/training/cat1/')))\n",
        "print(len(os.listdir('drive/My Drive/Data/training/cat2/')))\n",
        "print(len(os.listdir('drive/My Drive/Data/training/cat3/')))\n",
        "print(len(os.listdir('drive/My Drive/Data/testing/cat1/')))\n",
        "print(len(os.listdir('drive/My Drive/Data/testing/cat2/')))\n",
        "print(len(os.listdir('drive/My Drive/Data/testing/cat3/')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "216\n",
            "180\n",
            "188\n",
            "54\n",
            "46\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fig5ulc6hfw7",
        "colab_type": "code",
        "outputId": "0abb1339-281a-43c3-f403-5e2264e80c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"drive/My Drive/Data/training\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255)\n",
        "\n",
        "VALIDATION_DIR = \"drive/My Drive/Data/testing\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 584 images belonging to 3 classes.\n",
            "Found 145 images belonging to 3 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 72, 72, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 3,473,475\n",
            "Trainable params: 3,473,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "20/20 [==============================] - 690s 34s/step - loss: 1.9581 - accuracy: 0.3562 - val_loss: 1.1291 - val_accuracy: 0.3210\n",
            "Epoch 2/25\n",
            "20/20 [==============================] - 684s 34s/step - loss: 1.1201 - accuracy: 0.4435 - val_loss: 1.0876 - val_accuracy: 0.3875\n",
            "Epoch 3/25\n",
            "20/20 [==============================] - 685s 34s/step - loss: 1.0538 - accuracy: 0.5741 - val_loss: 1.1732 - val_accuracy: 0.3210\n",
            "Epoch 4/25\n",
            "20/20 [==============================] - 682s 34s/step - loss: 1.0355 - accuracy: 0.6383 - val_loss: 1.2223 - val_accuracy: 0.3026\n",
            "Epoch 5/25\n",
            "20/20 [==============================] - 682s 34s/step - loss: 0.6019 - accuracy: 0.7466 - val_loss: 1.2515 - val_accuracy: 0.3247\n",
            "Epoch 6/25\n",
            "20/20 [==============================] - 679s 34s/step - loss: 0.5331 - accuracy: 0.7868 - val_loss: 1.8790 - val_accuracy: 0.5277\n",
            "Epoch 7/25\n",
            "20/20 [==============================] - 681s 34s/step - loss: 0.5608 - accuracy: 0.7864 - val_loss: 1.9028 - val_accuracy: 0.4059\n",
            "Epoch 8/25\n",
            " 6/20 [========>.....................] - ETA: 6:16 - loss: 0.5371 - accuracy: 0.8127"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Ce9HL4kBDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBMCgzcHkGwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('areca1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}